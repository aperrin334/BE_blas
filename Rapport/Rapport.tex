\documentclass{report}

% Packages nécessaires
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{lipsum} % Package de remplissage de texte (à retirer dans le rapport final)
\usepackage{graphicx}
\usepackage{float} % pour l'option de placement [H]
\usepackage[colorlinks=true, linkcolor=blue, citecolor=green]{hyperref}
\usepackage{minted} % pour la coloration syntaxique
\usepackage{lipsum}
\usepackage{wrapfig}   % Pour l'enroulement du texte autour des images
\usepackage{array}

% Mathématiques
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{mdframed}  % Package pour les cadres


\newmdtheoremenv{boxedproperty}{Propriété}[section]  % Crée un environnement encadré pour les propriétés


% Configuration de la page
\usepackage[a4paper, left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}

% Pour avoir le petit dessin de l'INSA en bas à droite de chaque page
\usepackage{background}
\backgroundsetup{
scale=1,
angle=0,
opacity=1,
color=black,
contents={\begin{tikzpicture}[remember picture,overlay]
\node at ([xshift=-0.8in,yshift=0.8in] current page.south east) % Adjust the position of the logo.
{\includegraphics[scale=0.8]{images/pattern.png}}; % logo goes here
\end{tikzpicture}}
}


% Configuration des titres des sections et sous-sections
\titleformat{\chapter}[display]
  {\normalfont\Large\bfseries}{\chaptertitlename\thechapter}{14pt}{}
\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}

% Configuration de la table des matières
\renewcommand{\cftchapfont}{\bfseries}
\renewcommand{\cftsecfont}{\normalfont}
\renewcommand{\cftsubsecfont}{\normalfont}
\renewcommand{\cftchappagefont}{\bfseries}
\renewcommand{\cftsecpagefont}{\normalfont}
\renewcommand{\cftsubsecpagefont}{\normalfont}
\setlength{\cftbeforetoctitleskip}{0pt}
\setlength{\cftaftertoctitleskip}{10pt}
\renewcommand{\contentsname}{Table des matières}



\begin{document}


% Page de titre
\begin{titlepage}
    \centering

    % Minipages pour les logos
    \noindent % Assure qu'il n'y a pas d'indentation au début de la ligne
    \begin{minipage}{0.5\textwidth}
        \includegraphics[width=0.5\linewidth]{images/logo_INSA.png} % Ajustez le chemin et la taille
    \end{minipage}%
    \hfill % Assure que les deux minipages seront poussés à l'extrême gauche et droite
    \begin{minipage}{0.5\textwidth}
        \flushright % Alignement à droite dans la minipage
        \includegraphics[width=0.5\linewidth]{images/blanc.jpg} % Ajustez le chemin et la taille
    \end{minipage}


    \vspace*{2cm} % Espace vertical de 2 cm
    {\Huge\bfseries Optimisation et parallelisation OpenMP d'addition et produit
de deux matrices denses \par}
    \vspace{1cm}
    {\huge Rapport de Burreau d'étude\par}
    \vspace{2cm}
    {\Large \textbf{Luc-Christelle Nguyen et Alicia Perrin} \par}
    \vspace{2cm}
    
    {\Large \textbf{Institut National des Sciences Appliquées de Toulouse} \par}
    \vspace{1cm}
    {\large \today \par}
\end{titlepage}

% Résumé concis, souvent utilisé pour donner un aperçu rapide du contenu d'une recherche ou d'un article académique.
\begin{abstract}
    Dans ce rapport, nous présenterons différentes méthodes d’optimisation et de parallélisation appliquées aux calculs sur des matrices denses. Nous commencerons par étudier l’impact de l’ordre d’accès à la mémoire sur les performances, en exploitant la proximité spatiale des données afin d’améliorer l’utilisation du cache.Nous explorerons ensuite l’utilisation des bibliothèques OpenMP et OpenBLAS dans le but d’accélérer les calculs. L’analyse des trois niveaux de routines BLAS (BLAS1, BLAS2, BLAS3) mettra en évidence les gains considérables que l’on pourra obtenir grâce à OpenBLAS. Nous testerons également différentes stratégies de parallélisation (options static et dynamic) et nous étudierons l’impact du nombre de threads utilisés sur les performances globales. Enfin, nous mettrons en œuvre une optimisation basée sur la division en blocs (cache blocking) afin de mieux exploiter la hiérarchie mémoire.
\end{abstract}

% Table des matières
\tableofcontents

\newpage


\chapter{Modifier l'accès à la mémoire pour additionner deux matrices}

La première optimisation dont nous nous sommes servis utilise la proximité spatiale des informations. Nous avons fait en sorte que, pour l'addition de deux matrices, l'algorithme parcourt d'abord les colonnes et ensuite les lignes. En effet, une matrice est stockée en mémoire en column-major. Lorsque la fonction va aller chercher la première valeur de la matrice, elle va remplir le cache avec les valeurs suivantes. Ainsi, grâce à une bonne utilisation du cache, un grand nombre d'accès mémoire sont évités, ce qui permet d'augmenter la performance du programme.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig3.png}
    \caption{Différences de performances en fonction de l'ordre d'accès à la mémoire}
    \label{fig:3}
\end{figure}


On peut remarquer sur ces simulations que la rapidité de calcul a doublé en moyenne (cf \ref{fig:3}). C'est donc un critère important à prendre en compte lors de l'élaboration d'un programme.


\chapter{Compilation reliant les librairies OpenMP et BLAS}

Il y a trois routines BLAS (Basic Linear Algebra Subprograms) différentes, qui sont des fonctions standards pour effectuer des calculs de base en algèbre linéaire :
\begin{itemize}
    \item BLAS1 : ce sont des opérations vecteur-vecteur. Pour effectuer un produit matrice-matrice en utilisant uniquement des routines BLAS1, il faut appeler la routine pour chaque élément de la matrice résultat (car chaque élément est le produit scalaire d'une ligne et d'une colonne).
    \item BLAS2 : ce sont des opérations matrice-vecteur. Pour calculer un produit matrice-matrice avec des routines BLAS2, il faut appeler la routine pour chaque colonne de la matrice résultat.
    \item BLAS3 : ce sont des opérations matrice-matrice. Un seul appel de la routine permet de calculer tout le produit matriciel.
\end{itemize}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig1.png}
    \caption{Performances BLAS 1, 2, 3 sans optimisation Openblas}
    \label{fig:1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig2.png}
    \caption{Performances BLAS 1, 2, 3 avec optimisation Openblas}
    \label{fig:2}
\end{figure}

Lors de ces simulations, nous avons voulu premièrement montrer la différence d'efficacité entre les différents BLAS (cf. \ref{fig:1}). On remarque que BLAS3 est légèrement meilleure que les autres, du fait qu'il ne fait appel qu'à une seule fonction.
Puis nous avons voulu montrer la nette amélioration des performances lorsque nous utilisons la librairie OpenBLAS. C'est une version rapide et optimisée des routines BLAS. Elle utilise des optimisations spécifiques au processeur pour exploiter au mieux les instructions vectorielles et le calcul parallèle sur plusieurs cœurs. La différence de performance est énorme. Par exemple, pour BLAS3 la rapidité de calculs passe de 5Gflops à 400Gflops (cf \ref{fig:2}).

\chapter{Options de parallelisation d'un produit matriciel}

Dans cette partie, nous nous sommes concentrées sur l'optimisation par la parallélisation des tâches. Dans les simulations qui suivent, nous avons voulu tester les différentes options de parallélisation.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig4.png}
    \caption{Performances d'un calcul matriciel parallélisé avec l'option static et différents nombres de coeurs disponibles}
    \label{fig:4}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig5.png}
    \caption{Performances d'un calcul matriciel parallélisé avec l'option dynamic et différents nombres de coeurs disponibles}
    \label{fig:5}
\end{figure}

Nous pouvons remarquer que changer ces options n'a aucune influence réelle sur la performance du programme.

\chapter{Recherche du nombre de threads optimal pour BLAS3}

Dans cette partie nous nous sommes intéressées à l'influence du nombre de threads utilisés sur la rapidiré de calcul et le temps d'éxecution de BLAS3.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig6.png}
    \caption{Performance de BLAS3 en utilisant 1 à 12 threads lors de son éxecution}
    \label{fig:6}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/useCPU.png}
    \caption{Historique d'utilisation des threads pendant l'éxecution BLAS3}
    \label{fig:7}
\end{figure}

En faisant les simulations de BLAS3 avec 1 à 12 threads, nous observons que les performances de BLAS3 sont optimales lorsque le CPU utilise 6 threads sur les 12 disponibles (cf. \ref{fig:6}). En effet, en introduisant plus de 6 threads, les ressources sont partagées entre davantage de threads, ce qui diminue les performances de BLAS3.
De plus, en surveillant l'historique d'utilisation du CPU lors de l'exécution de BLAS3 avec 6 threads (cf. \ref{fig:7}), nous remarquons que, bien que 6 threads soient utilisés en permanence, ce ne sont pas les mêmes qui sont actifs tout au long de l'exécution.

\chapter{La cache blocking pour optimiser la multiplication matrice-matrice}

Dans le cadre de cette approche, nous cherchons à utiliser la mémoire cache de manière optimale en apportant des modifications à notre algorithme pour appliquer le principe de localité spatiale. Nous avons ainsi divisé les matrices en sous-blocs de taille adaptée au cache, permettant de maximiser la réutilisation des données dans les caches.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig7_dim.png}
    \caption{Performance de calculs en fonction de la taille de block utilisée pour différentes tailles de matrices}
    \label{fig:8}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/fig9.png}
    \caption{Performance de la méthode cache blocking, de BLAS3 et de la méthode de parallélisation}
    \label{fig:9}
\end{figure}

Nous nous sommes dans un premier temps penchées sur la taille de bloc optimale pour notre cache. En utilisant la méthode de blocking, nous cherchons à étudier les performances des calculs en fonction de la taille du bloc pour différentes tailles de matrices. Nous observons une taille de bloc optimal de 32 pour les petites dimensions (256 et 512) et de 64 pour les grandes dimensions.  Nous avons choisi de continuer nos simulations avec un bloc de taille 32 qui nous paraît un meilleur compromis entre les petites et grandes dimensions. En effet, avec un bloc de taille 64, on observe une chute importante de la performance pour les matrices de taille 512.  (cf. \ref{fig:8}).

Enfin, nous avons cherché à comparer les performances de cette méthode à celles de la parallélisation et de BLAS3 de la librairie OpenBLAS. On observe un seuil de taille de matrice à partir duquel les performances de BLAS3 sont bien meilleures que celles de la méthode de parallélisation ou de cache-blocking. Ce seuil se situe entre 750 et 1000 (cf. \ref{fig:9}). En dessous du seuil, c'est la méthode de cache blocking qui est plus performante, suivie de la parallélisation. À l'inverse. 
Les simulations démontrent la supériorité nette des méthodes de la librairie OpenBLAS pour optimiser les performances des calculs sur de grandes dimensions.

\end{document}